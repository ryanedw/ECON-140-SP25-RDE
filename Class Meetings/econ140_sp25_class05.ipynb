{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b834b122",
   "metadata": {},
   "source": [
    "<img src=\"images/econ140R_logo.png\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff12b62",
   "metadata": {},
   "source": [
    "<h1>ECON 140R Class 05</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c4cc7",
   "metadata": {},
   "source": [
    "Learning objectives:\n",
    "\n",
    "1. In <i>Mastering Metrics</i> Table 1.3, Angrist and Pischke use multivariate OLS to model 6 demographic characteristics and 5 baseline health characteristics (11 separate $y$ variables) on three indicator variables $D$ that measure assignment to treatment arms in the RAND Health Insurance Experiment, all of which have more generous insurance than the control group (\"catastrophic plan\")\n",
    "\n",
    "<p>\n",
    "\n",
    "2. The results in Table 1.3 show that the samples are <b>balanced</b>, meaning there are very few and practically zero statistically significant differences between the control and treatment groups\n",
    "    \n",
    "<p>\n",
    "\n",
    "3. A \"fine print\" detail is that Angrist and Pischke are doing what's called <i>clustering standard errors at the family level</i>. This last point will definitely not be on any exams\n",
    "  \n",
    "<p>\n",
    "    \n",
    "4. There also is clear evidence of traditional health inequalities <i>within</i> each group and within groups overall. For example, health is lower among respondents in the dataset who have less education\n",
    "\n",
    "<p>\n",
    "    \n",
    "5. Along the way, a call to `googlesheets4` to read in data that way too, and folks can also look at the public Sheets file if that's helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531711f-d826-4fce-80ac-9ccce141318f",
   "metadata": {},
   "source": [
    "Data from the 1974-1982 RAND Health Insurance Experiment (HIE) were unearthed by Aviva Aron-Dine, Liran Einav, and Amy Finkelstein (J. Econ. Perspect., 2013). Josh Angrist and J&#246;rn-Steffen Pischke provide an extract online at [Mastering Metrics](https://www.masteringmetrics.com/resources/).\n",
    "\n",
    "Let's examine the data behind Table 1.3, which shows baseline characteristics for the \"control group,\" people with catastrophic health insurance only (the leftmost column), and in subsequent columns, the average difference in the characteristic in that row between one of the three \"treatment arms\" they argue are useful to consider (deductible, coinsurance, free), and the control group.\n",
    "\n",
    "The objectives here are to get more experience with real data, and to notice that ordinary least squares regression with `lm()` is a very handy way to cut to the chase and test average differences across subgroups. A \"small print\" detail is that Angrist and Pischke are doing what's called <i>clustering standard errors at the family level</i>. This last point will definitely not be on any exams.\n",
    "\n",
    "The main objective is to recognize that with an outcome variable $y_i$ and group identity indicator variables $D^d_i$, $D^c_i$, and $D^f_i$, for example, then this regression:\n",
    "\n",
    "$$\n",
    "y_i = \\alpha + \\beta^d \\cdot D^d_i + \\beta^c \\cdot D^c_i + \\beta^f \\cdot D^f_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "provides a very convenient way of testing the average differences:\n",
    "* between the control group and group $d$: $\\beta^d$\n",
    "* between the control group and group $c$: $\\beta^c$\n",
    "* between the control group and group $f$: $\\beta^f$\n",
    "\n",
    "Here's a clean PNG of Table 1.3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75212122",
   "metadata": {},
   "source": [
    "<img src=\"images/MMtbl13.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb625c",
   "metadata": {},
   "source": [
    "Let's load up <b>haven</b> and <b>tidyverse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(haven)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec32e0",
   "metadata": {},
   "source": [
    "I have prepared an extract of the RAND HIE data underneath Table 1.3 in <i>Mastering Metrics</i>. These data include health care utilization outcomes across the four groups that Angrist and Pischke argue are usefully distinguishable, ordered here from least generous to most generous:\n",
    "\n",
    "* Catastrophic plan\n",
    "* Deductible plan\n",
    "* Coinsurance plan\n",
    "* Free plan\n",
    "\n",
    "We have the baseline background characteristics, and we also have baseline and end-of-study health status. The variables named with an \"-x\" at the end are the end-of-study measures, except where `ghindx` is baseline general health and thus `ghindxx` is end-of-study general health. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e742a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_3_0 <- read_dta(\"data/table1_3.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(table1_3_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d23774-ca9c-45f8-a4c7-5b574a0e2c0b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1df53-91d3-442f-a8b1-80c503885da8",
   "metadata": {},
   "source": [
    "<h2>Google Sheets for the win?</h2>\n",
    "\n",
    "It can also be useful to look at the data in Google Sheets. Many people learn best when they can use familiar tools to understand unfamiliar things. Here is a way to do that. First install a package and load it, then call `gs4_deauth()` to put `googlesheets4` into a deauthorized state and access a Sheets file that I made publicly viewable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abe740-6a77-4840-9df5-39a65fdd6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"googlesheets4\")\n",
    "library(googlesheets4)\n",
    "gs4_deauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38945695-3b95-41fe-8053-0e3d4c115966",
   "metadata": {},
   "source": [
    "This code reads in data from this publicly viewable Sheets file: [table1_3](https://docs.google.com/spreadsheets/d/1HGYLDtkW05ZD3vyh5S3HGNe3UKUSSMuLwBHHjS95LK0/edit?usp=sharing). The magic here is that you can just click this link and examine the file in Sheets, copy it, play Chutes and Ladders with it, and so on.\n",
    "\n",
    "By default `read_sheet()` will pull from the first tab in the Sheets file, or you can probably direct it to specific tabs and specific ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe904f0a-9db3-4dc4-a910-e1d6b09800a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1HGYLDtkW05ZD3vyh5S3HGNe3UKUSSMuLwBHHjS95LK0/edit?usp=sharing\"\n",
    "\n",
    "table1_3 <- read_sheet(sheet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402c0bb-d5dc-4340-9b67-444ee6dcae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(table1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8caffd",
   "metadata": {},
   "source": [
    "Let's create new data frames for each of the four groups using `filter()`. The shortened group names are:\n",
    "\n",
    "* `plan_catas` = Catastrophic plan \n",
    "* `plan_deduc` = Deductible plan   \n",
    "* `plan_coins` = Coinsurance plan  \n",
    "* `plan_free`  = Free plan   \n",
    "\n",
    "Copy and paste this code below and run it:\n",
    "\n",
    "`table1_3_catas <- filter(table1_3, plan_catas == 1)`\n",
    "\n",
    "`table1_3_deduc <- filter(table1_3, plan_deduc == 1)`\n",
    "\n",
    "`table1_3_coins <- filter(table1_3, plan_coins == 1)`\n",
    "\n",
    "`table1_3_free  <- filter(table1_3, plan_free  == 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_3_catas <- filter(table1_3_0, plan_catas == 1)\n",
    "\n",
    "table1_3_deduc <- filter(table1_3_0, plan_deduc == 1)\n",
    "\n",
    "table1_3_coins <- filter(table1_3_0, plan_coins == 1)\n",
    "\n",
    "table1_3_free  <- filter(table1_3_0, plan_free  == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fc917",
   "metadata": {},
   "source": [
    "What we now have are 4 separate data frames for the 4 groups assigned to different insurance plans.\n",
    "\n",
    "In STAT 20, you might have used `t.test()` to run a comparison between two groups. Let's run `t.test()` on the percent identifying as `female` in the deductible group versus the catastrophic group. This should get us something like the two numbers in the table at upper left.\n",
    "\n",
    "`t.test(table1_3_deduc$female, table1_3_catas$female)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(table1_3_deduc$female, table1_3_catas$female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f38c30",
   "metadata": {},
   "source": [
    "Not exactly clear, is it? The $t$-statistic is $-0.935, which in words means that this difference is about 0.935 times its standard error. That's not big enough for us to reject the null hypothesis that the true difference is zero. \n",
    "\n",
    "There's probably an option to `t.test()` that will show us this, but we can also just type it into __R__. Here is the difference between those last two numbers in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6479f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5368899 - 0.5599473"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee9a24",
   "metadata": {},
   "source": [
    "This is indeed the point estimate ($-0.023$) of the average difference that appears at the upper left of Table 1.3A.\n",
    "\n",
    "And then this, the difference divided by the $t$-stat, has to be the estimated standard error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fa89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.5368899 - 0.5599473)/-0.93539"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd8271",
   "metadata": {},
   "source": [
    "Unfortunately this is not the standard error $(.016)$ that appears under the $-0.023$ at the upper left of Table 1.3A. What's going on? Let's load in that new library, which will let us run a special version of `lm()` that will help reveal what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"estimatr\")\n",
    "library(estimatr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236116d1",
   "metadata": {},
   "source": [
    "First, let's run `lm_robust()` with options set to the baseline. The syntax is the same as it is for `lm()`, and we should recover the same results, as long as we set the standard errors to \"classical\" type.\n",
    "\n",
    "`reg_toprow <- lm(female ~ plan_deduc + plan_coins + plan_free, data = table1_3)`\n",
    "\n",
    "`summary(reg_toprow)`\n",
    "\n",
    "`reg_toprowrob <- lm_robust(female ~ plan_deduc + plan_coins + plan_free, \n",
    "                           data = table1_3, se_type = \"classical\")`\n",
    "\n",
    "`summary(reg_toprowrob)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_toprow <- lm(female ~ plan_deduc + plan_coins + plan_free, data = table1_3)\n",
    "\n",
    "summary(reg_toprow)\n",
    "\n",
    "reg_toprowrob <- lm_robust(female ~ plan_deduc + plan_coins + plan_free,                             data = table1_3, se_type = \"classical\")\n",
    "\n",
    "summary(reg_toprowrob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccf82e",
   "metadata": {},
   "source": [
    "Now let's explore what <i>clustering our standard errors at the family level</i> does to our estimates of the standard errors. Because there are families in these data, indexed by the `famid` variable, we might expect that the $\\epsilon$'s that shock a person one way or another within a family might shock the rest of the family as well. Imagine a family car that breaks down, so nobody keeps their checkup appointments.\n",
    "\n",
    "`reg_toprowcluster <- lm_robust(female ~ plan_deduc + plan_coins + plan_free, \n",
    "                                data = table1_3, clusters = famid)`\n",
    "                              \n",
    "`summary(reg_toprowcluster)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4078f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_toprowcluster <- lm_robust(female ~ plan_deduc + plan_coins + plan_free,                                  data = table1_3, clusters = famid)\n",
    "\n",
    "summary(reg_toprowcluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24696d15",
   "metadata": {},
   "source": [
    "Compare these results to the top row in Table 1.3A. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353179f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5dcf6ba",
   "metadata": {},
   "source": [
    "Compare these results to the results without clustering standard errors at the family level. Which standard errors are larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec932f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b707bff",
   "metadata": {},
   "source": [
    "<h3>A pause to reflect</h3>\n",
    "\n",
    "Notice that we ran this model::\n",
    "$$\n",
    "female_i = \\alpha + \\beta^d \\cdot D^d_i + \\beta^c \\cdot D^c_i + \\beta^f \\cdot D^f_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where the $D$'s are the 0/1 indicator variables showing membership in the treatment arms (deductible, coinsurance, free).\n",
    "\n",
    "Does it surprise or concern you at all that the $y$-variable, `female`, is <i>also</i> a 0/1 indicator variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0f910-ead1-422b-9ecf-d557fd545ea1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25f2460-4a2a-4ab6-8858-618c9feca07c",
   "metadata": {},
   "source": [
    "There are differences of opinion about this issue, and you should approach it with some caution, especially outside of economics. When we estimate a $y$ variable that takes on values of 0 or 1 with ordinary least squares, it is usually called a [linear probability model (LPM)](https://en.wikipedia.org/wiki/Linear_probability_model), and there are drawbacks to using it. The most obvious problem is that the prediction of the binary variable, $\\hat{y}$, is not guaranteed to be between 0 and 1. \n",
    "\n",
    "But the estimates of the slope coefficients $\\beta$ here are usually pretty accurate when comparing the LPM to estimates of marginal effects from a logit or probit model. The advantage is that the $\\beta$'s are much easier to interpret, and the same is not true of the coefficients in a nonlinear model like the logit or probit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fce80e",
   "metadata": {},
   "source": [
    "<h2>BONUS ROUND</h2>\n",
    "\n",
    "There are many other interesting things to look at here. We can also examine how baseline (before randomization) or end-of-study outcomes vary with characteristics, in a break with the RCT's advantages. But it can help us with practice and potentially some interesting thought experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc8bed",
   "metadata": {},
   "source": [
    "Here's a reproduction of the top line in panel B, where we are looking at the \"General health index\" `ghindx` across control and treatment arms:\n",
    "\n",
    "`reg_ghindxcluster <- lm_robust(ghindx ~ plan_deduc + plan_coins + plan_free,                                  \n",
    "                               data = table1_3, clusters = famid)`\n",
    "\n",
    "`summary(reg_ghindxcluster)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fdc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5454a8f9",
   "metadata": {},
   "source": [
    "It looks like we've got the right variable. Maybe we can try this model of health:\n",
    "\n",
    "$$\n",
    "ghindx_{i0} = \\alpha + \\beta^a \\cdot age_i + \\beta^f \\cdot female_i + \\beta^bh \\cdot blackhisp_i + \\beta^e \\cdot educ_i +\n",
    "\\beta^i \\cdot income_{i0} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where I'm using $i0$ to refer to the measure of a variable for person $i$ at time $0$, meaning before the RCT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb640a3a",
   "metadata": {},
   "source": [
    "`reg_ghindx_yc <- lm_robust(ghindx ~ age + female + blackhisp + educper + income1cpi,                                  \n",
    "                               data = table1_3, clusters = famid)`\n",
    "\n",
    "`summary(reg_ghindx_yc)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75834c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b170411b",
   "metadata": {},
   "source": [
    "Write about what you see here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107de324",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "    In the entire pooled sample, we see rather large health inequalities at baseline. That's probably great news, because the reason we're looking at this at all is to inform policy about the health insurance status of real people. And among real people, there are big health inequalities.\n",
    "</font>\n",
    "<p>\n",
    "<font color=\"red\">\n",
    "    For a randomized controlled trial (RCT) to work, we need to have the control and treatment groups look the same <i>on average</i>. Within each group, there still will be and should be patterns between variables. Randomization means that the treatment variable of interest is applied only to the treatment group(s).\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab6640",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <span style=\"font-family:Papyrus; \">And they lived happily ever after. The End.</span></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
